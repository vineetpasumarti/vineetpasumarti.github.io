<!DOCTYPE HTML>
<html lang="en">

<head>
    <title>Image2GPS | Vineet Pasumarti</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <style>
        #main .container {
            text-align: left;
        }

        table {
            margin-top: 1em;
            border-collapse: collapse;
        }

        th,
        td {
            border: 1px solid #ccc;
            padding: 0.5em;
        }

        caption {
            font-weight: bold;
            margin-bottom: 0.5em;
        }
    </style>
</head>

<body class="is-preload">

    <!-- Header -->
    <div id="header">

        <div class="top">

            <!-- Nav -->
            <nav id="nav">
                <ul>
                    <!-- <li><a href="#top" id="top-link"><span class="icon solid fa-home">Intro</span></a></li> -->
                    <li><a href="index.html#about" id="about-link"><span class="icon solid fa-user">Vineet
                                Pasumarti</span></a>
                    </li>
                    <li><a href="index.html#projects" id="portfolio-link"><span
                                class="icon solid fa-th">Projects</span></a>
                    </li>
                    <li><a href="index.html#resume" id="resume-link"><span
                                class="icon solid fa-file">Resume/CV</span></a>
                    </li>
                    <li><a href="index.html#contact" id="contact-link"><span
                                class="icon solid fa-envelope">Contact</span></a>
                    </li>
                </ul>
            </nav>

        </div>

        <div class="bottom">

            <!-- Social Icons -->
            <ul class="icons">
                <!-- <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li> -->
                <!-- <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li> -->
                <li><a href="https://github.com/vineetpasumarti" class="icon brands fa-github"><span
                            class="label">Github</span></a></li>
                <li><a href="https://www.linkedin.com/in/vineetpasumarti/" class="icon brands fa-linkedin"><span
                            class="label">LinkedIn</span></a></li>
                <li><a href="index.html#contact" class="icon solid fa-envelope"><span class="label">Email</span></a>
                </li>
            </ul>

        </div>

    </div>

    <!-- Main -->
    <div id="main">
        <section class="three">
            <div class="container">
                <header style="margin-bottom: 0.2em;">
                    <h2 class="alt" style="margin-bottom: 0;"><strong>Learning Emergent Obstacle Avoidance and
                            Competitive Drone Racing Behaviors from
                            Sparse Rewards</strong></h2>
                </header>


                <p>
                    In progress. Full work and arXiv coming soon...
                </p>

                <div style="text-align: center;">
                    <img src="images/hq_circle-track-dr.gif" alt="Project Image"
                        style="max-width: 100%; width: auto; border-radius: 5px; margin-bottom: 1em;" />
                </div>


                <p>
                    We present a reinforcement learning approach for competitive autonomous drone racing that leverages
                    multi-agent dynamics to achieve superior performance through emergent behaviors. Unlike existing
                    methods that rely on dense, progress-based reward functions and treat racing as a single-agent
                    time-trial optimization problem, we demonstrate that a sparse, competition-based reward structure in
                    multi-agent settings naturally produces more robust and adaptive racing strategies. Our key finding
                    is that training drones to compete directly against adversaries, rather than optimizing lap times in
                    isolation, leads to emergent obstacle avoidance behaviors and more efficient trajectory optimization
                    without explicit reward shaping. Through extensive experiments in simulation and real-world
                    deployment on Crazyflie 2.1 platforms, we show that policies trained with our sparse multi-agent
                    rewards exhibit superior generalization to complex tracks with obstacles compared to single-agent
                    baselines. The competitive pressure inherent in head-to-head racing eliminates the need for
                    carefully engineered reward terms that often fail in novel environments, particularly those with
                    unexpected obstacles. Our approach achieves robust sim-to-real transfer while learning overtaking
                    maneuvers, defensive blocking, and collision avoidance as natural byproducts of the optimization
                    process, demonstrating that multi-agent training with sparse rewards provides a more scalable path
                    for unstructured and complex racing environments.
                </p>



            </div>
        </section>
    </div>

    <!-- Footer -->
    <div id="footer">
        <ul class="copyright">
            <li>&copy; 2025 Vineet Pasumarti</li>
        </ul>
    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>